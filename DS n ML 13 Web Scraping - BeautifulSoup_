{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":959,"status":"ok","timestamp":1649231049965,"user":{"displayName":"Prashant Pande","userId":"16701808208088080373"},"user_tz":-330},"id":"3pbCQeyhz_gJ"},"outputs":[],"source":["import pandas as pd\n","from bs4 import BeautifulSoup\n","import requests\n","import time\n","import re"]},{"cell_type":"code","source":["html = '<!DOCTYPE html><html><head><title>Learning Beautiful Soup</title></head>\\\n","<body><h1> About Us </h1><div class = \"first_div\"><p>Coding Ninjas Website</p>\\\n","<a href=\"https://www.codingninjas.in/\">Link to Coding Ninjas Website</a>\\\n","<ul><li>This</li><li>is</li><li>an</li><li>unordered</li><li>list.</li></ul>\\\n","</div><p id = \"template_p\">This is a template paragraph tag</p>\\\n","<a href = \"https://www.facebook.com/codingninjas/\">\\\n","This is the link of our Facebook Page</a></body></html>'"],"metadata":{"id":"tIObHabFYwW_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Soup = BeautifulSoup(html, 'html.parser')\n","print(Soup.body)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FeAaazc7ZBuL","executionInfo":{"status":"ok","timestamp":1647794891017,"user_tz":-330,"elapsed":3,"user":{"displayName":"Prashant Pande","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggs0XwlEd7jz18eVMYXoVH8DoNqcdfFHTh2O5FAbA=s64","userId":"16701808208088080373"}},"outputId":"3fc70673-6a9e-4f3e-f9ac-98a16add4989"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<body><h1> About Us </h1><div class=\"first_div\"><p>Coding Ninjas Website</p><a href=\"https://www.codingninjas.in/\">Link to Coding Ninjas Website</a><ul><li>This</li><li>is</li><li>an</li><li>unordered</li><li>list.</li></ul></div><p id=\"template_p\">This is a template paragraph tag</p><a href=\"https://www.facebook.com/codingninjas/\">This is the link of our Facebook Page</a></body>\n"]}]},{"cell_type":"code","source":["Attr = Soup.div.attrs\n","for i in Attr :\n","    print(i)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"upqE7lX2ZeWH","executionInfo":{"status":"ok","timestamp":1647794893588,"user_tz":-330,"elapsed":408,"user":{"displayName":"Prashant Pande","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggs0XwlEd7jz18eVMYXoVH8DoNqcdfFHTh2O5FAbA=s64","userId":"16701808208088080373"}},"outputId":"a43850d0-40b4-456b-96eb-a68382e7e626"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["class\n"]}]},{"cell_type":"code","source":["l = Soup.find_all('li')\n","for i in l :\n","    print(i.string,end=' ')"],"metadata":{"id":"OEgRQHWNbhs6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647512505989,"user_tz":-330,"elapsed":457,"user":{"displayName":"Prashant Pande","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggs0XwlEd7jz18eVMYXoVH8DoNqcdfFHTh2O5FAbA=s64","userId":"16701808208088080373"}},"outputId":"df6bbd75-9b6f-47d7-a2c3-6fff608ad78c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["This is an unordered list. "]}]},{"cell_type":"code","source":["l = Soup.find_all('a')\n","for i in l :\n","    print(i.attrs['href'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FXBcRgKEuTzP","executionInfo":{"status":"ok","timestamp":1647512508722,"user_tz":-330,"elapsed":975,"user":{"displayName":"Prashant Pande","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggs0XwlEd7jz18eVMYXoVH8DoNqcdfFHTh2O5FAbA=s64","userId":"16701808208088080373"}},"outputId":"c495d3d3-6285-431d-ac63-7ad0fa085b8f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["https://www.codingninjas.in/\n","https://www.facebook.com/codingninjas/\n"]}]},{"cell_type":"code","source":["HTML = '<!DOCTYPE html><html><head><title>Navigate Parse Tree</title></head>\\\n","<body><h1>This is your Assignment</h1><a href = \"https://www.google.com\">This is a link that will take you to Google</a>\\\n","<ul><li><p> This question is given to test your knowledge of <b>Web Scraping</b></p>\\\n","<p>Web scraping is a term used to describe the use of a program or algorithm to extract and process large amounts of data from the web.</p></li>\\\n","<li id = \"li2\">This is an li tag given to you for scraping</li>\\\n","<li>This li tag gives you the various ways to get data from a website\\\n","<ol><li class = \"list_or\">Using API of the website</li><li>Scrape data using BeautifulSoup</li><li>Scrape data using Selenium</li>\\\n","<li>Scrape data using Scrapy</li></ol></li>\\\n","<li class = \"list_or\"><a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\">\\\n","Clicking on this takes you to the documentation of BeautifulSoup</a>\\\n","<a href=\"https://selenium-python.readthedocs.io/\" id=\"anchor\">Clicking on this takes you to the documentation of Selenium</a>\\\n","</li></ul></body></html>'"],"metadata":{"id":"-C6yYc_ikLRa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["DATA = BeautifulSoup(HTML, 'html.parser')\n","Child = list(DATA.html.children)\n","desc = list(DATA.html.descendants)\n","print(len(desc)-len(Child))"],"metadata":{"id":"ZmK3bwNK85ew","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647709109318,"user_tz":-330,"elapsed":433,"user":{"displayName":"Prashant Pande","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggs0XwlEd7jz18eVMYXoVH8DoNqcdfFHTh2O5FAbA=s64","userId":"16701808208088080373"}},"outputId":"8094709f-776a-4ddf-b4f6-80bedf3c37e5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["32\n"]}]},{"cell_type":"code","source":["Id_attr = DATA.find_all(id=True)\n","for id in Id_attr :\n","    print(id.name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-KYOwiB9izPj","executionInfo":{"status":"ok","timestamp":1647512515529,"user_tz":-330,"elapsed":4,"user":{"displayName":"Prashant Pande","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggs0XwlEd7jz18eVMYXoVH8DoNqcdfFHTh2O5FAbA=s64","userId":"16701808208088080373"}},"outputId":"9a785b3f-eb5e-4221-d9b8-2e1b5b570849"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["li\n","a\n"]}]},{"cell_type":"code","source":["content = DATA.find(id='li2').next_siblings\n","for i in content :\n","    print(i)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r0hOTbOIl1hs","executionInfo":{"status":"ok","timestamp":1647512521684,"user_tz":-330,"elapsed":600,"user":{"displayName":"Prashant Pande","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggs0XwlEd7jz18eVMYXoVH8DoNqcdfFHTh2O5FAbA=s64","userId":"16701808208088080373"}},"outputId":"712bfbfa-d006-4c40-ceaf-0e35ebafe12c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<li>This li tag gives you the various ways to get data from a website<ol><li class=\"list_or\">Using API of the website</li><li>Scrape data using BeautifulSoup</li><li>Scrape data using Selenium</li><li>Scrape data using Scrapy</li></ol></li>\n","<li class=\"list_or\"><a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\">Clicking on this takes you to the documentation of BeautifulSoup</a><a href=\"https://selenium-python.readthedocs.io/\" id=\"anchor\">Clicking on this takes you to the documentation of Selenium</a></li>\n"]}]},{"cell_type":"code","source":["Title = DATA.title\n","for parent in Title.parents :\n","    print(parent)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YsKm4b3jnOrz","executionInfo":{"status":"ok","timestamp":1647512525000,"user_tz":-330,"elapsed":487,"user":{"displayName":"Prashant Pande","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggs0XwlEd7jz18eVMYXoVH8DoNqcdfFHTh2O5FAbA=s64","userId":"16701808208088080373"}},"outputId":"53ece855-4649-430d-ec22-129315cf1d29"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<head><title>Navigate Parse Tree</title></head>\n","<html><head><title>Navigate Parse Tree</title></head><body><h1>This is your Assignment</h1><a href=\"https://www.google.com\">This is a link that will take you to Google</a><ul><li><p> This question is given to test your knowledge of <b>Web Scraping</b></p><p>Web scraping is a term used to describe the use of a program or algorithm to extract and process large amounts of data from the web.</p></li><li id=\"li2\">This is an li tag given to you for scraping</li><li>This li tag gives you the various ways to get data from a website<ol><li class=\"list_or\">Using API of the website</li><li>Scrape data using BeautifulSoup</li><li>Scrape data using Selenium</li><li>Scrape data using Scrapy</li></ol></li><li class=\"list_or\"><a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\">Clicking on this takes you to the documentation of BeautifulSoup</a><a href=\"https://selenium-python.readthedocs.io/\" id=\"anchor\">Clicking on this takes you to the documentation of Selenium</a></li></ul></body></html>\n","<!DOCTYPE html>\n","<html><head><title>Navigate Parse Tree</title></head><body><h1>This is your Assignment</h1><a href=\"https://www.google.com\">This is a link that will take you to Google</a><ul><li><p> This question is given to test your knowledge of <b>Web Scraping</b></p><p>Web scraping is a term used to describe the use of a program or algorithm to extract and process large amounts of data from the web.</p></li><li id=\"li2\">This is an li tag given to you for scraping</li><li>This li tag gives you the various ways to get data from a website<ol><li class=\"list_or\">Using API of the website</li><li>Scrape data using BeautifulSoup</li><li>Scrape data using Selenium</li><li>Scrape data using Scrapy</li></ol></li><li class=\"list_or\"><a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\">Clicking on this takes you to the documentation of BeautifulSoup</a><a href=\"https://selenium-python.readthedocs.io/\" id=\"anchor\">Clicking on this takes you to the documentation of Selenium</a></li></ul></body></html>\n"]}]},{"cell_type":"code","source":["sec = DATA.find_all('a')[1]\n","print(sec.next_element)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cTRvH2CvpETE","executionInfo":{"status":"ok","timestamp":1647512527496,"user_tz":-330,"elapsed":449,"user":{"displayName":"Prashant Pande","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggs0XwlEd7jz18eVMYXoVH8DoNqcdfFHTh2O5FAbA=s64","userId":"16701808208088080373"}},"outputId":"4f1c4f98-3933-46bf-c81d-ae7b253ccc98"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Clicking on this takes you to the documentation of BeautifulSoup\n"]}]},{"cell_type":"code","source":["resp = requests.get(\"http://info.cern.ch/hypertext/WWW/TheProject.html\")\n","html_data = resp.text\n","data = BeautifulSoup(html_data, 'html.parser')"],"metadata":{"id":"xM01mInbqoBT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(data.h1.text)\n","print(data.title)\n","print(data.a['href'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5nJeS0rP6Suw","executionInfo":{"status":"ok","timestamp":1647512532472,"user_tz":-330,"elapsed":460,"user":{"displayName":"Prashant Pande","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggs0XwlEd7jz18eVMYXoVH8DoNqcdfFHTh2O5FAbA=s64","userId":"16701808208088080373"}},"outputId":"a3b82dbf-7b56-4b25-f128-463dc8fc1cea"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["World Wide Web\n","<title>The World Wide Web project</title>\n","WhatIs.html\n"]}]},{"cell_type":"code","source":["li = data.find_all('a')\n","print(len(li))\n","for i in li :\n","    print(i.text, end=' ')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZjvVKv_68ddE","executionInfo":{"status":"ok","timestamp":1647512535148,"user_tz":-330,"elapsed":450,"user":{"displayName":"Prashant Pande","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggs0XwlEd7jz18eVMYXoVH8DoNqcdfFHTh2O5FAbA=s64","userId":"16701808208088080373"}},"outputId":"6c8bfdd9-df5e-43d3-fae6-9899aa3ffd13"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["25\n","\n","hypermedia executive\n","summary Mailing lists Policy W3  news Frequently Asked Questions What's out there?  subjects W3 servers Help Software Products Line Mode Viola NeXTStep Servers Tools  Mail robot \n","Library Technical Bibliography People History How can I help Getting code \n","anonymous FTP "]}]},{"cell_type":"code","source":["li_2 = data.dl.find_all('a')\n","for j in li_2 :\n","    print(j.text, end=' ')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L6RLqzoj-gcj","executionInfo":{"status":"ok","timestamp":1647512537055,"user_tz":-330,"elapsed":5,"user":{"displayName":"Prashant Pande","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggs0XwlEd7jz18eVMYXoVH8DoNqcdfFHTh2O5FAbA=s64","userId":"16701808208088080373"}},"outputId":"bec4b67c-c396-4244-9317-6a88d0c6844a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["What's out there?  subjects W3 servers Help Software Products Line Mode Viola NeXTStep Servers Tools  Mail robot \n","Library Technical Bibliography People History How can I help Getting code \n","anonymous FTP "]}]},{"cell_type":"code","source":["Resp = requests.get(\"https://books.toscrape.com/\")\n","Html_data = Resp.text\n","Data = BeautifulSoup(Html_data, \"html.parser\")\n","# print(Data.prettify())"],"metadata":{"id":"rL7ncqKj_Vb2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(Data.header.a)\n","print(Data.header.a.string)\n","print(Data.h1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XfiWx6ldBSMZ","executionInfo":{"status":"ok","timestamp":1647512542912,"user_tz":-330,"elapsed":659,"user":{"displayName":"Prashant Pande","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggs0XwlEd7jz18eVMYXoVH8DoNqcdfFHTh2O5FAbA=s64","userId":"16701808208088080373"}},"outputId":"0b3af00c-5ee9-4bd5-f522-cc27acd9c1e7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<a href=\"index.html\">Books to Scrape</a>\n","Books to Scrape\n","<h1>All products</h1>\n"]}]},{"cell_type":"code","source":["b1 = Data.find(class_ = 'product_pod')\n","print(b1.h3)\n","print(b1.h3.a)\n","print(b1.h3.a['title'])\n","print(b1.h3.a['href'])\n","print(\"https://books.toscrape.com/\" + b1.h3.a['href'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l5wy1-VOD3xL","executionInfo":{"status":"ok","timestamp":1647512550344,"user_tz":-330,"elapsed":530,"user":{"displayName":"Prashant Pande","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggs0XwlEd7jz18eVMYXoVH8DoNqcdfFHTh2O5FAbA=s64","userId":"16701808208088080373"}},"outputId":"987d5720-e1da-4689-dc57-f2736c4485c9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<h3><a href=\"catalogue/a-light-in-the-attic_1000/index.html\" title=\"A Light in the Attic\">A Light in the ...</a></h3>\n","<a href=\"catalogue/a-light-in-the-attic_1000/index.html\" title=\"A Light in the Attic\">A Light in the ...</a>\n","A Light in the Attic\n","catalogue/a-light-in-the-attic_1000/index.html\n","https://books.toscrape.com/catalogue/a-light-in-the-attic_1000/index.html\n"]}]},{"cell_type":"code","source":["# Problem 10 : Book Names from First Page\n","books = Data.find_all(class_ = 'product_pod')\n","print(len(books))\n","for i in books :\n","    print(i.h3.a['title'])"],"metadata":{"id":"hqZ4fvgiFXhg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Problem 11 : All Categories\n","Catagory = Data.find(class_=\"side_categories\")\n","Cat = Catagory.find_all('a')\n","for x in Cat :\n","    if x.string.strip() != \"Books\":\n","        print(x.string.strip())"],"metadata":{"id":"3dTpdriwIoM9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["all_urls = [\"http://books.toscrape.com/catalogue/page-1.html\"]\n","current_page = \"http://books.toscrape.com/catalogue/page-1.html\"\n","base_url = \"http://books.toscrape.com/catalogue/\"\n","response = requests.get(current_page)\n","\n","while response.status_code == 200 :\n","    data = BeautifulSoup(response.text, 'html.parser')\n","    next_page = data.find(class_='next')\n","    if next_page is None :\n","        break\n","    next_page_url = base_url + next_page.a['href']\n","    print(next_page_url)\n","    all_urls.append(next_page_url)\n","    current_page = next_page_url\n","    response = requests.get(current_page)"],"metadata":{"id":"Y1bX5x-tdmBs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Problem 12 : All Book Names\n","allPages = ['http://books.toscrape.com/catalogue/page-1.html',\n","            'http://books.toscrape.com/catalogue/page-2.html',\n","            'http://books.toscrape.com/catalogue/page-3.html',\n","            'http://books.toscrape.com/catalogue/page-4.html',\n","            'http://books.toscrape.com/catalogue/page-5.html',\n","            'http://books.toscrape.com/catalogue/page-6.html',\n","            'http://books.toscrape.com/catalogue/page-7.html',\n","            'http://books.toscrape.com/catalogue/page-8.html',\n","            'http://books.toscrape.com/catalogue/page-9.html',\n","            'http://books.toscrape.com/catalogue/page-10.html']\n","\n","for i in range(10) :\n","    resp = requests.get(allPages[i])\n","    data = BeautifulSoup(resp.text, 'html.parser')\n","    books = data.find_all(class_ = \"product_pod\")\n","    for i in books :\n","        print(i.h3.a['title'])"],"metadata":{"id":"MCl9kjECjOk6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["base_url = \"http://books.toscrape.com/\"\n","RESP = requests.get(base_url)\n","DATA = BeautifulSoup(RESP.text, 'html.parser')\n","B1 = DATA.find(class_='product_pod')\n","B1_url = base_url + B1.h3.a['href']\n","response = requests.get(B1_url)\n","data = BeautifulSoup(response.text, 'html.parser')\n","B1_title = data.h1.string\n","B1_price = data.find(class_='price_color').string\n","B1_qty = data.find(class_='instock availability') \n","B1_qty = B1_qty.contents[-1].strip()\n","B1_qty = int(re.search('\\d+', B1_qty).group())\n","B1_price = float(re.search('[\\d.]+', B1_price).group())\n","Book_details = []\n","Book_details.append([B1_title, B1_url, B1_price, B1_qty])\n","Book_details.append([B1_title, B1_url, B1_price, B1_qty])\n","Book_details.append([B1_title, B1_url, B1_price, B1_qty])\n","df = pd.DataFrame(Book_details, columns = ['Title', 'URL', 'Price of Book', 'Quantity in Stock'])\n","print(B1_url)\n","df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":161},"id":"QSHJhjRTf_hS","executionInfo":{"status":"ok","timestamp":1647537289424,"user_tz":-330,"elapsed":1426,"user":{"displayName":"Prashant Pande","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggs0XwlEd7jz18eVMYXoVH8DoNqcdfFHTh2O5FAbA=s64","userId":"16701808208088080373"}},"outputId":"651172df-bd5a-4f68-fa8b-6ced0b0745a2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["http://books.toscrape.com/catalogue/a-light-in-the-attic_1000/index.html\n"]},{"output_type":"execute_result","data":{"text/plain":["                  Title                                                URL  \\\n","0  A Light in the Attic  http://books.toscrape.com/catalogue/a-light-in...   \n","1  A Light in the Attic  http://books.toscrape.com/catalogue/a-light-in...   \n","2  A Light in the Attic  http://books.toscrape.com/catalogue/a-light-in...   \n","\n","   Price of Book  Quantity in Stock  \n","0          51.77                 22  \n","1          51.77                 22  \n","2          51.77                 22  "],"text/html":["\n","  <div id=\"df-0ea0c999-42a1-4774-91c0-0cfbeae798fb\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Title</th>\n","      <th>URL</th>\n","      <th>Price of Book</th>\n","      <th>Quantity in Stock</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>A Light in the Attic</td>\n","      <td>http://books.toscrape.com/catalogue/a-light-in...</td>\n","      <td>51.77</td>\n","      <td>22</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>A Light in the Attic</td>\n","      <td>http://books.toscrape.com/catalogue/a-light-in...</td>\n","      <td>51.77</td>\n","      <td>22</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>A Light in the Attic</td>\n","      <td>http://books.toscrape.com/catalogue/a-light-in...</td>\n","      <td>51.77</td>\n","      <td>22</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0ea0c999-42a1-4774-91c0-0cfbeae798fb')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-0ea0c999-42a1-4774-91c0-0cfbeae798fb button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-0ea0c999-42a1-4774-91c0-0cfbeae798fb');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["allPages = ['http://books.toscrape.com/catalogue/page-1.html',\n","            'http://books.toscrape.com/catalogue/page-2.html']\n","\n","column_names = ['Title', 'Link', 'Price', 'Quantity in Stock']\n","\n","base_url = \"http://books.toscrape.com/catalogue/\"\n","Book_details = []\n","for i in range(2) :\n","    response = requests.get(allPages[i])\n","    data = BeautifulSoup(response.text, 'html.parser')\n","    books = data.find_all(class_='product_pod')\n","    for book in books :\n","        book_url = base_url + book.h3.a['href']\n","        B_resp = requests.get(book_url)\n","        B_data = BeautifulSoup(B_resp.text, 'html.parser')\n","        B_title = B_data.h1.string\n","        B_link = book_url\n","        B_price = B_data.find(class_='price_color').string\n","        B_qty = B_data.find(class_='instock availability')\n","        B_qty = B_qty.contents[-1].strip()\n","        B_qty = int(re.search('\\d+', B_qty).group())\n","        B_price = float(re.search('[\\d.]+', B_price).group())\n","        Book_details.append([B_title, B_link, B_price, B_qty])\n","\n","df = pd.DataFrame(Book_details, columns=column_names)\n","for i in range(len(df)):\n","    print(df['Title'][i],df['Link'][i],df['Price'][i],df['Quantity in Stock'][i])"],"metadata":{"id":"EzMyaOzouiyr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["allPages = ['http://books.toscrape.com/catalogue/page-1.html','http://books.toscrape.com/catalogue/page-2.html']\n","column_names = ['Title', 'Link', 'Price', 'Quantity in Stock']\n","base_url = 'http://books.toscrape.com/catalogue/'\n","\n","allBooks=[]\n","for i in allPages:\n","    response = requests.get(i)\n","    data = BeautifulSoup(response.text, 'html.parser')\n","    book = data.find_all(class_='product_pod')\n","    for i in book:\n","        b_url = base_url + i.h3.a['href']\n","        allBooks.append(b_url)\n","      \n","Book_details=[]\n","for i in allBooks:\n","    response = requests.get(i)\n","    data = BeautifulSoup(response.text, 'html.parser')\n","    title = data.h1.string\n","    price = data.find(class_='price_color').string\n","    qty = data.find(class_='instock availability')\n","    qty = qty.contents[-1].strip()\n","    qty = int(re.search('\\d+',qty).group())\n","    price = float(re.search('[\\d.]+',price).group())\n","    Book_details.append([title, i, price, qty])\n","    \n","#for i in Book_details:\n","#print(*i)\n","df = pd.DataFrame(Book_details,columns=column_names)\n","for i in range(len(df)):\n","    print(df['Title'][i],df['Link'][i],df['Price'][i],df['Quantity in Stock'][i])"],"metadata":{"id":"W2jEVIn49TNV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["resp = requests.get(\"https://www.imdb.com/search/title/?release_date=2018&sort=num_votes,desc&page=1&ref_=adv_nxt\")\n","data = BeautifulSoup(resp.text, 'html.parser')\n","title = data.find_all(class_='lister-item-header')[:3]\n","genre = data.find_all(class_='genre')[:3]\n","for i in range(3) :\n","    print(title[i].find('a').string+' ;', end = ' ')\n","    print(genre[i].string.strip())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kpdZMoSS8fKO","executionInfo":{"status":"ok","timestamp":1647539910442,"user_tz":-330,"elapsed":1727,"user":{"displayName":"Prashant Pande","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggs0XwlEd7jz18eVMYXoVH8DoNqcdfFHTh2O5FAbA=s64","userId":"16701808208088080373"}},"outputId":"71b4ce54-a650-4dd8-847b-b9dc658a3ac1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Avengers: Infinity War ; Action, Adventure, Sci-Fi\n","Black Panther ; Action, Adventure, Sci-Fi\n","Deadpool 2 ; Action, Adventure, Comedy\n"]}]},{"cell_type":"code","source":["urls = ['https://www.imdb.com/search/title/?release_date=2010-01-01,2010-12-31&sort=num_votes,desc&ref_=adv_prv',\n","        'https://www.imdb.com/search/title/?release_date=2011-01-01,2011-12-31&sort=num_votes,desc&ref_=adv_prv',\n","       'https://www.imdb.com/search/title/?release_date=2012-01-01,2012-12-31&sort=num_votes,desc&ref_=adv_prv',\n","        'https://www.imdb.com/search/title/?release_date=2013-01-01,2013-12-31&sort=num_votes,desc&ref_=adv_prv',\n","       'https://www.imdb.com/search/title/?release_date=2014-01-01,2014-12-31&sort=num_votes,desc&ref_=adv_prv']\n","for i in range(5) :\n","    Resp = requests.get(urls[i])\n","    Data = BeautifulSoup(Resp.text, 'html.parser')\n","    name = Data.find(class_='lister-item-content').a.string\n","    print(name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BBZCQclh_dtG","executionInfo":{"status":"ok","timestamp":1647541864988,"user_tz":-330,"elapsed":15615,"user":{"displayName":"Prashant Pande","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggs0XwlEd7jz18eVMYXoVH8DoNqcdfFHTh2O5FAbA=s64","userId":"16701808208088080373"}},"outputId":"8693404b-c4c2-4e43-d7f5-aa3bd5885858"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Inception\n","Game of Thrones\n","The Dark Knight Rises\n","The Wolf of Wall Street\n","Interstellar\n"]}]},{"cell_type":"code","source":["urls = [\"https://www.imdb.com/search/title/?release_date=2018-01-01,2018-12-31&sort=num_votes,desc&start=1&ref_=adv_nxt\",\n","       \"https://www.imdb.com/search/title/?release_date=2018-01-01,2018-12-31&sort=num_votes,desc&start=51&ref_=adv_nxt\",\n","       \"https://www.imdb.com/search/title/?release_date=2018-01-01,2018-12-31&sort=num_votes,desc&start=101&ref_=adv_nxt\",\n","       \"https://www.imdb.com/search/title/?release_date=2018-01-01,2018-12-31&sort=num_votes,desc&start=151&ref_=adv_nxt\",\n","       \"https://www.imdb.com/search/title/?release_date=2018-01-01,2018-12-31&sort=num_votes,desc&start=201&ref_=adv_nxt\"]\n","\n","Dict = {}\n","for i in range(5) :\n","    Resp = requests.get(urls[i])\n","    data = BeautifulSoup(Resp.text, \"html.parser\")\n","    Title = data.find_all(class_='lister-item-content')\n","    Dur = data.find_all(class_='runtime')\n","    for i in range(len(Dur)) :\n","        title = Title[i].find('a').string\n","        dur = Dur[i].string\n","        dur = int(dur.strip().split(' ')[0])\n","        Dict[title] = dur\n","Maxdur = -1\n","for T, dur in Dict.items() :\n","    if dur > Maxdur :\n","        Maxdur = dur\n","        Maxtitle = T\n","print(Maxtitle, Maxdur)"],"metadata":{"id":"FAcIx-rKJYpk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647687771900,"user_tz":-330,"elapsed":6237,"user":{"displayName":"Prashant Pande","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggs0XwlEd7jz18eVMYXoVH8DoNqcdfFHTh2O5FAbA=s64","userId":"16701808208088080373"}},"outputId":"0156acd2-b8cd-465a-ad27-e1dcd3cfc688"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The Haunting of Hill House 572\n"]}]},{"cell_type":"code","source":["# Problem : Image with maximum area\n","url = \"https://en.wikipedia.org/wiki/Artificial_intelligence\"\n","Resp = requests.get(url)\n","data = BeautifulSoup(Resp.text, 'html.parser')\n","img_data = data.find_all('img')\n","Max_area = -1\n","src = ''\n","for i in img_data :\n","    if i.has_attr('height') and i.has_attr('width') :\n","        if int(i['height']) * int(i['width']) > Max_area :\n","            Max_area = int(i['height']) * int(i['width'])\n","            src = i['src']\n","print(src)"],"metadata":{"id":"6osS-mZqZkHT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647709279968,"user_tz":-330,"elapsed":1450,"user":{"displayName":"Prashant Pande","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggs0XwlEd7jz18eVMYXoVH8DoNqcdfFHTh2O5FAbA=s64","userId":"16701808208088080373"}},"outputId":"3688550c-033b-425d-f009-10caa0af8da5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["//upload.wikimedia.org/wikipedia/commons/6/69/EM_Clustering_of_Old_Faithful_data.gif\n"]}]},{"cell_type":"code","source":["# Problem : Quotes with tag humor\n","URL = [\"https://quotes.toscrape.com/tag/humor/page/1/\",\"https://quotes.toscrape.com/tag/humor/page/2/\"]\n","for i in range(2) :\n","    Resp = requests.get(URL[i])\n","    Soup = BeautifulSoup(Resp.text, 'html.parser')\n","    Q = Soup.find_all(class_=\"text\")\n","    for i in Q :\n","        print(i.text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XRMb05tkHnVS","executionInfo":{"status":"ok","timestamp":1647710738271,"user_tz":-330,"elapsed":670,"user":{"displayName":"Prashant Pande","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggs0XwlEd7jz18eVMYXoVH8DoNqcdfFHTh2O5FAbA=s64","userId":"16701808208088080373"}},"outputId":"28715ad5-2e80-4efc-b6d4-679a33254fde"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”\n","“A day without sunshine is like, you know, night.”\n","“Anyone who thinks sitting in church can make you a Christian must also think that sitting in a garage can make you a car.”\n","“Beauty is in the eye of the beholder and it may be necessary from time to time to give a stupid or misinformed beholder a black eye.”\n","“All you need is love. But a little chocolate now and then doesn't hurt.”\n","“Remember, we're madly in love, so it's all right to kiss me anytime you feel like it.”\n","“Some people never go crazy. What truly horrible lives they must lead.”\n","“The trouble with having an open mind, of course, is that people will insist on coming along and trying to put things in it.”\n","“Think left and think right and think low and think high. Oh, the thinks you can think up if only you try!”\n","“The reason I talk to myself is because I’m the only one whose answers I accept.”\n","“I am free of all prejudice. I hate everyone equally. ”\n","“A lady's imagination is very rapid; it jumps from admiration to love, from love to matrimony in a moment.”\n"]}]},{"cell_type":"code","source":["# \n","All_urls = ['http://quotes.toscrape.com/page/1/']\n","base = 'http://quotes.toscrape.com'\n","\n","Resp = requests.get(All_urls[0])\n","while Resp.status_code == 200 :\n","    data = BeautifulSoup(Resp.text, \"html.parser\")\n","    if data.find(class_=\"next\") is None :\n","        break\n","    next_url = base + data.find(class_='next').a['href']\n","    All_urls.append(next_url)\n","    Resp = requests.get(All_urls[-1])\n","Authers = []\n","for i in All_urls :\n","    Response = requests.get(i)\n","    Data = BeautifulSoup(Response.text, \"html.parser\")\n","\n","    for j in Data.find_all(class_=\"quote\") :\n","        name = j.find(class_='author').string\n","        if name not in Authers :\n","            Authers.append(name)\n","\n","for x in sorted(Authers) :\n","    print(x, end= '  ')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Htof5PtUI4At","executionInfo":{"status":"ok","timestamp":1647712948288,"user_tz":-330,"elapsed":2126,"user":{"displayName":"Prashant Pande","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggs0XwlEd7jz18eVMYXoVH8DoNqcdfFHTh2O5FAbA=s64","userId":"16701808208088080373"}},"outputId":"60b0ecc7-1f7f-43e0-e10f-14bcd5c24f5c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Albert Einstein  Alexandre Dumas fils  Alfred Tennyson  Allen Saunders  André Gide  Ayn Rand  Bob Marley  C.S. Lewis  Charles Bukowski  Charles M. Schulz  Douglas Adams  Dr. Seuss  E.E. Cummings  Eleanor Roosevelt  Elie Wiesel  Ernest Hemingway  Friedrich Nietzsche  Garrison Keillor  George Bernard Shaw  George Carlin  George Eliot  George R.R. Martin  Harper Lee  Haruki Murakami  Helen Keller  J.D. Salinger  J.K. Rowling  J.M. Barrie  J.R.R. Tolkien  James Baldwin  Jane Austen  Jim Henson  Jimi Hendrix  John Lennon  Jorge Luis Borges  Khaled Hosseini  Madeleine L'Engle  Marilyn Monroe  Mark Twain  Martin Luther King Jr.  Mother Teresa  Pablo Neruda  Ralph Waldo Emerson  Stephenie Meyer  Steve Martin  Suzanne Collins  Terry Pratchett  Thomas A. Edison  W.C. Fields  William Nicholson  "]}]},{"cell_type":"code","source":["Authers = {}\n","for i in range(1,11) :\n","    resp = requests.get(\"https://quotes.toscrape.com/page/\"+str(i)+\"/\")\n","    Data = BeautifulSoup(resp.text, \"html.parser\")\n","    for Auth in Data.select('.author') :\n","        if Auth.text[0] == 'J' :\n","            Authers[Auth.text] = Auth.next_sibling.next_sibling['href']\n","\n","Auth_Birth = {}\n","for auth in sorted(Authers) :\n","    RESP = requests.get(\"https://quotes.toscrape.com\" + Authers[auth])\n","    DATA = BeautifulSoup(RESP.text, \"html.parser\")\n","    for x in DATA.select('.author-born-date') :\n","        Auth_Birth[auth] = x.text\n","print(Auth_Birth)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ym5P76RYUaxw","executionInfo":{"status":"ok","timestamp":1647715273107,"user_tz":-330,"elapsed":4159,"user":{"displayName":"Prashant Pande","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggs0XwlEd7jz18eVMYXoVH8DoNqcdfFHTh2O5FAbA=s64","userId":"16701808208088080373"}},"outputId":"336b8f6e-2783-4ae9-a34f-8c5d51e17feb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'J.D. Salinger': 'January 01, 1919', 'J.K. Rowling': 'July 31, 1965', 'J.M. Barrie': 'May 09, 1860', 'J.R.R. Tolkien': 'January 03, 1892', 'James Baldwin': 'August 02, 1924', 'Jane Austen': 'December 16, 1775', 'Jim Henson': 'September 24, 1936', 'Jimi Hendrix': 'November 27, 1942', 'John Lennon': 'October 09, 1940', 'Jorge Luis Borges': 'August 24, 1899'}\n"]}]},{"cell_type":"code","source":["# Quotes by Albert Einstein\n","url = \"https://quotes.toscrape.com/page/\"\n","for i in range(1,11) :\n","    resp = requests.get(url+str(i)+'/')\n","    data = BeautifulSoup(resp.text, \"html.parser\")\n","    for x in data.find_all(class_='quote') :\n","        auth_name = x.find(class_='author').string\n","        if auth_name == 'Albert Einstein' :\n","            print(x.find(class_='text').string)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3Q-HNgJValv2","executionInfo":{"status":"ok","timestamp":1648838018371,"user_tz":-330,"elapsed":1533,"user":{"displayName":"Prashant Pande","userId":"16701808208088080373"}},"outputId":"c93d5787-0d59-4773-a150-d3bbafbc876b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”\n","“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”\n","“Try not to become a man of success. Rather become a man of value.”\n","“If you can't explain it to a six year old, you don't understand it yourself.”\n","“If you want your children to be intelligent, read them fairy tales. If you want them to be more intelligent, read them more fairy tales.”\n","“Logic will get you from A to Z; imagination will get you everywhere.”\n","“Any fool can know. The point is to understand.”\n","“Life is like riding a bicycle. To keep your balance, you must keep moving.”\n","“If I were not a physicist, I would probably be a musician. I often think in music. I live my daydreams in music. I see my life in terms of music.”\n","“Anyone who has never made a mistake has never tried anything new.”\n"]}]},{"cell_type":"code","source":["url = \"http://books.toscrape.com/\"\n","Resp = requests.get(url)\n","Soup = BeautifulSoup(Resp.text, 'html.parser')\n","Catagory = Soup.find(class_='side_categories')\n","Cat = Catagory.find_all('a')\n","for i in Cat :\n","    if i.string.strip() != 'Books' :\n","        print(i.string.strip())"],"metadata":{"id":"cjHcM56pjVoC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["URL = \"https://medium.com/codingninjas-blog\"\n","import requests\n","from bs4 import BeautifulSoup\n","Resp = requests.get(URL)\n","Soup = BeautifulSoup(Resp.text, 'html.parser')\n","Blogs = Soup.find_all(class_='section-content') \n","for i in range(5): \n","    print(Blogs[i].find(\"h3\").text)"],"metadata":{"id":"VQ5JdFhhQMgx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649232964055,"user_tz":-330,"elapsed":445,"user":{"displayName":"Prashant Pande","userId":"16701808208088080373"}},"outputId":"c6eaa83d-d593-4927-940a-82b409fc4f98"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Web Development Trends to watch out for in 2020\n","Web Development: Interviews and You!\n","Get equipped for the Technical Interviews\n","Explore more about the projects in Web Development\n","5G to be a major gamechanger for Edu-tech platforms\n"]}]}],"metadata":{"colab":{"collapsed_sections":[],"name":"DS n ML 13 Web Scraping - BeautifulSoup ","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}